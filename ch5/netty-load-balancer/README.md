# 안정해시설계(consistent hashing)

## 배경

```
(처리율 제한 장치에서와 같은 배경)
이번에는 이 스트리머가 라이브 방송을 진행했을 때, 시청자들의 요청(부하)을 분산시키는 설계를 해야한다.
이 스트리머는 한국에서 인기있는 스트리머이다.
따라서 라이브 방송이 시작되면 한국의 데이터센터(엣지, CDN)에서 다량의 실시간 데이터 요청이 발생할 것이다.

앞서 언급했듯이 이 스트리머의 시청자 수는 최소 1만 5천 명 ~ 최대 8만 5천 명이다.
하나의 CDN(엣지)만 사용했을 경우 이 부하를 모두 받게 되면 서버가 다운될 것이고, 
스트리밍 중계 서버로 부하가 집중되어 시스템이 마비될 것이다.
따라서 한국 지역에 관한 CDN은 적절히 스케일 아웃 하고 부하 분산(Load Balancing)을 해야 한다.
```

## 하드웨어 스팩

```
CPU 모델 : Intel(R) Xeon(R) Silver 4214
CPU 클럭 : 2.20GHz
CPU 아키텍처 : x86_64
CPU 개수 : 4개
CPU 코어 개수 : 12개 (총 48개 코어)
CPU 코어 당 스레드 개수 : 2개 (총 96개 스레드)
RAM : 376GB
보조 저장장치 : 5TB
```

## 하드웨어 스팩과 비용계산(버추얼 노드 개수)을 통한 스케일 아웃 개수 결정

```
먼저 사용자 수는 최소 인원인 1만 5천명으로 가정한다.
왜냐하면 스케일 아웃의 경우 클라우드를 사용하여 빠르게 늘릴수 있기 때문에
최소한의 비용으로 시작하여 부하가 집중될 수록 점차 비용을 늘려가는게 낫다고 판단했다.

스트리머의 방송 화질은 720p이라 할때, 이 영상의 비트레이트 별 데이터 사용량은 아래와 같다.
```

| 화질 | 비트레이트 (Mbps) | 데이터 사용량 (GB/시간) |
|----|--------------|-----------------|
| 낮음 | 2 Mbps       | 0.9 GB          |
| 보통 | 3 Mbps       | 1.35 GB         |
| 높음 | 4 Mbps       | 1.8 GB          |
| 최고 | 5 Mbps       | 2.25 GB         |

```
스트리머는 이 중 중간값(보통값)인 3Mbps를 사용한다고 가정하자. 
그렇다면 720p 화질로 시간당 1.35GB의 데이터를 보내게 된다.

여기에 오디오 데이터에 관한 데이터도 추가해야한다.
오디오 품질별 샘플링 레이트, 비트레이트, 데이터 사용량은 아래와 같다.
```

| 오디오 품질     | 샘플링 레이트   | 비트레이트 (Kbps) | 데이터 사용량 (MB/시간) |
|------------|-----------|--------------|-----------------|
| 낮음 (음성 위주) | 22.05 kHz | 64 Kbps      | 28.8 MB         |
| 보통 (일반 음질) | 44.1 kHz  | 128 Kbps     | 57.6 MB         |
| 높음 (고음질)   | 48 kHz    | 192 Kbps     | 86.4 MB         |
| 최고 (스튜디오급) | 48 kHz 이상 | 256 Kbps     | 115.2 MB        |

```
오디오 품질도 일반음질을 사용한다고 가정하자.
그렇다면 비트레이트는 128kbps로 시간당 57.6MB의 음성을 전송한다.

따라서 보통 영상(3 Mbps)과 보통 오디오(128 Kbps) 데이터를 합산하면 시간당 1.41GB가 사용된다.
이 스트리머는 하루에 최대 6시간 정도 방송한다고 가정하면, 8.46GB의 데이터가 전송된다.

최소 인원인 1만 5천명이 6시간 동안 라이브 방송을 시청한다고 가정하고,
HLS에 의해 트랜스코딩된 데이터 세그먼트가 6초 길이라고 가정하면 
6초 영상의 용량은 2.35MB이므로 하나의 CDN에 1만5천명이 동시에 요청한다면
총 데이터 전송량 = 2.35MB × 15,000 = 35,250MB = 35.25GB가 된다.

일단, 단순하게 메모리에 캐싱하고 TTL 설정이 없다고 가정하자. 
그러면 총 영상은 35.25GB의 3600배로써 126,900GB가 된다.
이는 337.5배에 해당한다. 단순 램만으로 캐싱한다고 했을 때 최소한 338개의 서버가 필요한 것이다.
이는 말도 안되는 수치와 비용이 들어간다. 

이 영상은 라이브스트리밍 영상이다, 즉 특수한 목적이 있다.
과거의 영상으로 되돌아가는 것은 빈번하지 않고 대부분의 사용자들이 최신 영상을 본다. 
즉, TTL(Time To Live)을 사용하여 램의 용량을 아낄 수 있다.
영상의 길이는 6초이고 대략 90%의 인원이 과거의 데이터를 요청안하고 최신데이터만 요청한다고 가정하자.
이는 1만 3천 5백명이고 나머지 1천5백명을 위한 과거데이터가 필요한 것이다.

일단은 TTL을 18초로 가정하였다. 이는 세그먼트 3개에 해당하는 길이이다.
대부분의 시청자들은 최신 데이터에 머물 것이라 가정하였고,
나머지 시청자들은 네트워크 지연률을 대략 반영하더라도 두 개의 세그먼트보다 더 뒤쪽에 있지 않을거라 가정하였다.
영상의 총 세그먼트는 3600개인데, 18초 마다 하나의 세그먼트가 메모리에서 지워지므로
이를 계산할 경우 한번에 적재되는 메모리 양은 2개 세그먼트에 해당하는 7.05MB이다.
다른 영상들도 캐시되어있다고 가정한다면 합리적인 크기라는 생각이 든다.

이제 메모리에 관한 고려는 끝났으므로, 네트워크 대역폭을 고려해야 한다.
보통 CDN 서버는 고속 네트워크 환경에서 동작하지만, 
이를 추정하기 위해 일반적인 1Gbps(약 125MB/s) 대역폭을 기준으로 계산해보자.
1Gbps의 대역폭을 가진 서버가 초당 전송할 수 있는 데이터는 125MB이다.
만약 서버가 동시에 15,000명의 요청을 처리하려면, 
한 세그먼트 크기 2.35MB를 15,000명이 동시에 요청할 경우 587.5MB/s이 되어야 한다.
단일 서버의 대역폭이 125MB/s라고 했을 때, 587.5MB/s를 전송하려면 약 5배 이상의 서버가 필요하다.

결론)
 1) TTL 18초, 
 2) 대역폭 1Gbps(약 125MB/s)를 기준으로 최소 5개의 서버로 스케일 아웃, 최대 30개까지 스케일 아웃
 
그렇다면 로드밸런서의 key를 클라이언트의 IP Address라고 가정하면 대략 몇 개의 virtual node가 좋을까?
각 virtual node는 대략 8KB ~ 16KB 정도의 메모리가 사용된다. 
376GB 램의 15%정도까지 사용가능하고 최대 사용자수까지 고려하여, 
246,760개의 virtual node의 개수가 좋을거 같다.
```
